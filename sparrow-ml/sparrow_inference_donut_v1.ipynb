{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Set-up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Function to find the correct image path\n",
    "def find_image_path(base_path, image_name):\n",
    "    for root, dirs, files in os.walk(base_path):\n",
    "        if image_name in files:\n",
    "            return os.path.join(root, image_name)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Load image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"katanaml-org/invoices-donut-data-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the image path from the dataset\n",
    "image_path = dataset['test'][10]['image']\n",
    "image_name = os.path.basename(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base directory of the project\n",
    "base_path = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))  # Ajusta esto segÃºn sea necesari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import os\n",
    "\n",
    "# Get the image path or URL\n",
    "image_path_or_url = dataset['test'][10]['image']\n",
    "\n",
    "# Define the base path\n",
    "base_path = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "\n",
    "# Function to find the correct image path\n",
    "def find_image_path(base_path, image_name):\n",
    "    for root, dirs, files in os.walk(base_path):\n",
    "        if image_name in files:\n",
    "            return os.path.join(root, image_name)\n",
    "    return None\n",
    "\n",
    "# Get the image name from the path\n",
    "image_name = os.path.basename(image_path_or_url)\n",
    "\n",
    "# Find the correct image path\n",
    "correct_image_path = find_image_path(base_path, image_name)\n",
    "\n",
    "if correct_image_path:\n",
    "    image = Image.open(correct_image_path)\n",
    "else:\n",
    "    print(f\"Image not found: {image_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_image_path = find_image_path(base_path, image_name)\n",
    "correct_image_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Load model and processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from transformers import DonutProcessor, VisionEncoderDecoderModel\n",
    "\n",
    "if correct_image_path:\n",
    "    print(f\"Imagen encontrada en: {correct_image_path}\")\n",
    "    \n",
    "    # Open the image\n",
    "    image = Image.open(correct_image_path)\n",
    "    \n",
    "else:\n",
    "    print(f\"No se pudo encontrar la imagen: {image_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Prepare using processor\n",
    "We prepare the image for the model using DonutProcessor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DonutProcessor, VisionEncoderDecoderModel\n",
    "\n",
    "# Load the processor and the model\n",
    "processor = DonutProcessor.from_pretrained(\"katanaml-org/invoices-donut-model-v1\")\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"katanaml-org/invoices-donut-model-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of pixel_values: torch.Size([1, 3, 1280, 960])\n"
     ]
    }
   ],
   "source": [
    "# Process the image\n",
    "pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n",
    "print(f\"Shape of pixel_values: {pixel_values.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Generate\n",
    "Finally, we let the model autoregressively generate the structured data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\miniconda3\\envs\\sparrow-donut\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:615: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structured Output:\n",
      "{\n",
      "  \"header\": {\n",
      "    \"invoice_no\": \"48902311\",\n",
      "    \"invoice_date\": \"03/31/2016\",\n",
      "    \"seller\": \"Hill Group 47445 Tiffany Canyon Suite 530 Lake Carolyn, MN 88734\",\n",
      "    \"client\": \"Calhoun PLC 692 Pittman Square Apt. 121 Victorfort, KY 65016\",\n",
      "    \"seller_tax_id\": \"964-97-3541\",\n",
      "    \"client_tax_id\": \"961-78-6129\",\n",
      "    \"iban\": \"GB57H5XH62221465152779\"\n",
      "  },\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"item_desc\": \"2,00\",\n",
      "      \"item_net_price\": \"89,99\",\n",
      "      \"item_net_worth\": \"179,98\",\n",
      "      \"item_vat\": \"10%\",\n",
      "      \"item_gross_worth\": \"197,98\"\n",
      "    },\n",
      "    {\n",
      "      \"item_desc\": \"1,00\",\n",
      "      \"item_net_price\": \"8,99\",\n",
      "      \"item_net_worth\": \"8,99\",\n",
      "      \"item_vat\": \"10%\",\n",
      "      \"item_gross_worth\": \"9,89\"\n",
      "    },\n",
      "    {\n",
      "      \"item_desc\": \"2,00\",\n",
      "      \"item_net_price\": \"2,99\",\n",
      "      \"item_net_worth\": \"5,98\",\n",
      "      \"item_vat\": \"10%\",\n",
      "      \"item_gross_worth\": \"6,58\"\n",
      "    },\n",
      "    {\n",
      "      \"item_desc\": \"3,00\",\n",
      "      \"item_net_price\": \"34,99\",\n",
      "      \"item_net_worth\": \"104,97\",\n",
      "      \"item_vat\": \"10%\",\n",
      "      \"item_gross_worth\": \"115,47\"\n",
      "    },\n",
      "    {\n",
      "      \"item_desc\": \"1,00\",\n",
      "      \"item_net_price\": \"12,00\",\n",
      "      \"item_net_worth\": \"12,00\",\n",
      "      \"item_vat\": \"10%\",\n",
      "      \"item_gross_worth\": \"13,20\"\n",
      "    },\n",
      "    {\n",
      "      \"item_desc\": \"5,00\",\n",
      "      \"item_net_price\": \"44,99\",\n",
      "      \"item_net_worth\": \"224,95\",\n",
      "      \"item_vat\": \"10%\",\n",
      "      \"item_gross_worth\": \"247,45\"\n",
      "    },\n",
      "    {\n",
      "      \"item_desc\": \"2,00\",\n",
      "      \"item_net_price\": \"25,00\",\n",
      "      \"item_net_worth\": \"50,00\",\n",
      "      \"item_vat\": \"10%\",\n",
      "      \"item_gross_worth\": \"55,00\"\n",
      "    }\n",
      "  ],\n",
      "  \"summary\": {\n",
      "    \"total_net_worth\": \"$ 586,87\",\n",
      "    \"total_vat\": \"$58,69\",\n",
      "    \"total_gross_worth\": \"$ 645,56\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Generate output\n",
    "task_prompt = \"<s_cord-v2>\"\n",
    "decoder_input_ids = processor.tokenizer(task_prompt, add_special_tokens=False, return_tensors=\"pt\")[\"input_ids\"]\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "try:\n",
    "    outputs = model.generate(\n",
    "        pixel_values.to(device),\n",
    "        decoder_input_ids=decoder_input_ids.to(device),\n",
    "        max_length=model.decoder.config.max_position_embeddings,\n",
    "        early_stopping=True,\n",
    "        pad_token_id=processor.tokenizer.pad_token_id,\n",
    "        eos_token_id=processor.tokenizer.eos_token_id,\n",
    "        use_cache=True,\n",
    "        num_beams=1,\n",
    "        bad_words_ids=[[processor.tokenizer.unk_token_id]],\n",
    "        return_dict_in_generate=True,\n",
    "        output_scores=True,\n",
    "    )\n",
    "\n",
    "    # Process the output\n",
    "    sequence = processor.batch_decode(outputs.sequences)[0]\n",
    "    sequence = sequence.replace(processor.tokenizer.eos_token, \"\").replace(processor.tokenizer.pad_token, \"\")\n",
    "    sequence = re.sub(r\"<.*?>\", \"\", sequence, count=1).strip()  # remove first task start token\n",
    "\n",
    "    # Convert to JSON\n",
    "    try:\n",
    "        # We can convert the generated sequence to JSON if required:\n",
    "        json_output = processor.token2json(sequence)\n",
    "        print(\"Structured Output:\")\n",
    "        print(json.dumps(json_output, indent=2))\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting to JSON: {e}\")\n",
    "        print(\"Raw sequence:\")\n",
    "        print(sequence)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during generation: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
